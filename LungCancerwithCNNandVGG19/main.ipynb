{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import imageio.v2 as imageio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, RepeatedStratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from skimage import segmentation\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import load_img, img_to_array, array_to_img, plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting memory consumption growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'./LungCancerDataset/The IQ-OTHNCCD lung cancer dataset'\n",
    "\n",
    "categories = ['Bengin cases', 'Malignant cases', 'Normal cases']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Size Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_data = {}\n",
    "for i in categories:\n",
    "    path = os.path.join(directory, i)\n",
    "    class_num = categories.index(i)\n",
    "    temp_dict = {}\n",
    "    for file in os.listdir(path):\n",
    "        filepath = os.path.join(path, file)\n",
    "        height, width, channels = imageio.imread(filepath).shape\n",
    "        if str(height) + ' x ' + str(width) in temp_dict:\n",
    "            temp_dict[str(height) + ' x ' + str(width)] += 1 \n",
    "        else:\n",
    "            temp_dict[str(height) + ' x ' + str(width)] = 1\n",
    "    \n",
    "    size_data[i] = temp_dict\n",
    "        \n",
    "size_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categories:\n",
    "    path = os.path.join(directory, i)\n",
    "    class_num = categories.index(i)\n",
    "    for file in os.listdir(path):\n",
    "        filepath = os.path.join(path, file)\n",
    "        print(i)\n",
    "        img = cv2.imread(filepath, 0)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "for i in categories:\n",
    "    cnt, samples = 0, 3\n",
    "    fig, ax = plt.subplots(samples, 3, figsize=(15, 15))\n",
    "    fig.suptitle(i)\n",
    "    \n",
    "    path = os.path.join(directory, i)\n",
    "    class_num = categories.index(i)\n",
    "    for curr_cnt, file in enumerate(os.listdir(path)):\n",
    "        filepath = os.path.join(path, file)\n",
    "        img = cv2.imread(filepath, 0)\n",
    "        \n",
    "        img0 = cv2.resize(img, (img_size, img_size))\n",
    "        \n",
    "        img1 = cv2.GaussianBlur(img0, (5, 5), 0)\n",
    "        \n",
    "        ax[cnt, 0].imshow(img)\n",
    "        ax[cnt, 1].imshow(img0)\n",
    "        ax[cnt, 2].imshow(img1)\n",
    "        cnt += 1\n",
    "        if cnt == samples:\n",
    "            break\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "img_size = 256\n",
    "\n",
    "for i in categories:\n",
    "    path = os.path.join(directory, i)\n",
    "    class_num = categories.index(i)\n",
    "    for file in os.listdir(path):\n",
    "        filepath = os.path.join(path, file)\n",
    "        img = cv2.imread(filepath, 0)\n",
    "        # preprocess here\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        data.append([img, class_num])\n",
    "        \n",
    "random.shuffle(data)\n",
    "\n",
    "X, y = [], []\n",
    "for feature, label in data:\n",
    "    X.append(feature)\n",
    "    y.append(label)\n",
    "    \n",
    "print('X length:', len(X))\n",
    "print('y counts:', Counter(y))\n",
    "\n",
    "# normalize\n",
    "X = np.array(X).reshape(-1, img_size, img_size, 1)\n",
    "X = X / 255.0\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=10)\n",
    "\n",
    "print('Train length:', len(X_train), X_train.shape)\n",
    "print('Test length:', len(X_valid), X_valid.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying SMOTE to oversample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(y_train), Counter(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train), X_train.shape)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_size*img_size*1)\n",
    "\n",
    "print(len(X_train), X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before SMOTE:', Counter(y_train))\n",
    "smote = SMOTE()\n",
    "X_train_sampled, y_train_sampled = smote.fit_resample(X_train, y_train)\n",
    "print('After SMOTE:', Counter(y_train_sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_size, img_size, 1)\n",
    "X_train_sampled = X_train_sampled.reshape(X_train_sampled.shape[0], img_size, img_size, 1)\n",
    "\n",
    "print(len(X_train), X_train.shape)\n",
    "print(len(X_train_sampled), X_train_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "val_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=8, shuffle=True) \n",
    "validation_generator = val_datagen.flow(X_valid, y_valid, batch_size=8, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained VGG19 model without the top classification layer\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Create a new model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the VGG19 base model\n",
    "model.add(base_model)\n",
    "\n",
    "# Add your own classification layers on top\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple early stopping\n",
    "callback = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = {\n",
    "    0: X_train.shape[0]/(3*Counter(y_train)[0]),\n",
    "    1: X_train.shape[0]/(3*Counter(y_train)[1]),\n",
    "    2: X_train.shape[0]/(3*Counter(y_train)[2]),\n",
    "}\n",
    "\n",
    "# new_weights[0] = 0.5\n",
    "# new_weights[1] = 20\n",
    "\n",
    "new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model, show_shapes= True, show_dtype= True, show_layer_activations= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=20, validation_data=validation_generator, class_weight=new_weights, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_valid, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_valid, y_pred_bool))\n",
    "print(confusion_matrix(y_true=y_valid, y_pred=y_pred_bool))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
