{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import imageio.v2 as imageio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.applications import resnet\n",
    "from keras.applications import EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.morphology import remove_small_objects, remove_small_holes, ball, disk, dilation, binary_erosion, erosion, closing, reconstruction, binary_closing, binary_dilation, binary_opening\n",
    "from skimage import morphology, filters, measure, feature, segmentation, color , io , exposure\n",
    "from skimage.filters import try_all_threshold, roberts, sobel\n",
    "from skimage.color import gray2rgb , rgb2gray\n",
    "from skimage.segmentation import clear_border\n",
    "import scipy.misc\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting memory consumption growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'./iqothnccd-lung-cancer-dataset/The IQ-OTHNCCD lung cancer dataset/'\n",
    "\n",
    "categories = ['Bengin cases', 'Malignant cases', 'Normal cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def hist(image, title='Image'):\n",
    "    '''Function for draw historgrame for values in image'''\n",
    "    fig,ax= plt.subplots(figsize=(20,7),nrows=1,ncols=1)\n",
    "    ax.hist(image.ravel(),bins=30,color='gray')\n",
    "    ax.spines.top.set_visible(False)\n",
    "    ax.spines.right.set_visible(False)\n",
    "    \n",
    "    \n",
    "def show(img, title='Image'):\n",
    "    '''Function for visualize sigle image'''\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def load_scans(INPUT_FOLDER):\n",
    "    '''Function for load scans'''\n",
    "    imgs=[]\n",
    "    for i in os.listdir(INPUT_FOLDER):\n",
    "        imgs.append(cv2.imread(INPUT_FOLDER+'/'+i))\n",
    "    return imgs\n",
    "\n",
    "def show_slices(st,rows,cols):\n",
    "    '''Function to load multiple images'''\n",
    "    fig, axs = plt.subplots(rows,cols,figsize=(rows+5,cols+5))\n",
    "    axs = axs.flatten()\n",
    "    for i in range(rows*cols):\n",
    "        axs[i].imshow(st[i],cmap='gray')\n",
    "        axs[i].axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def normalize(gray):\n",
    "    '''Functoin for make all values in image between 0 and 1'''\n",
    "    MIN_BOUND = gray.min()\n",
    "    MAX_BOUND = gray.max()\n",
    "    gray = (gray - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    gray[gray>1] = 1.\n",
    "    gray[gray<0] = 0.\n",
    "    return gray"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Size Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_data = {}\n",
    "for i in categories:\n",
    "    path = os.path.join(directory, i)\n",
    "    class_num = categories.index(i)\n",
    "    temp_list = []\n",
    "    for file in os.listdir(path):\n",
    "        filepath = os.path.join(path, file)\n",
    "        height, width, channels = io.imread(filepath).shape\n",
    "        temp_list.append(f\"{height} x {width}\")\n",
    "    \n",
    "    size_data[i] = dict(Counter(temp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert size_data to a pandas DataFrame\n",
    "df = pd.DataFrame.from_dict(size_data, orient='index')\n",
    "\n",
    "# Use Seaborn to create the first bar plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15, 6))\n",
    "sns.barplot(data=df.T, errorbar=None, ax=ax1)\n",
    "ax1.set(xlabel='Category', ylabel='Count', title='Images Distribution by Category')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Use Seaborn to create the second bar plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.barplot(data=df, errorbar=None, ax=ax2)\n",
    "ax2.set(xlabel='Image Size', ylabel='Count', title='Image Size Distribution')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Adjust the layout of the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malignant_folder= f'./iqothnccd-lung-cancer-dataset/The IQ-OTHNCCD lung cancer dataset/Malignant cases'\n",
    "data = load_scans(malignant_folder)\n",
    "show_slices(data , 2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(data[7])\n",
    "hist(data[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = try_all_threshold(rgb2gray(data[7]), figsize=(10, 8), verbose=False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Segmentation Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import measure\n",
    "\n",
    "def filter_labels(labels, nlabels):\n",
    "    corners = find_corners(labels)\n",
    "    object_sizes = calculate_objects_size(labels, corners)\n",
    "    sorted_sizes = sort_labels_by_size(object_sizes)\n",
    "    filtered_sizes = remove_small_objects(sorted_sizes)\n",
    "    diaphragm_label = remove_diaphragm(labels, filtered_sizes)\n",
    "    cleaned_labels = create_cleaned_labels(labels, filtered_sizes)\n",
    "    left_label, right_label = get_left_and_right_labels(cleaned_labels)\n",
    "    \n",
    "    return [left_label, right_label]\n",
    "\n",
    "\n",
    "def find_corners(labels):\n",
    "    h, w = labels.shape[:2]\n",
    "    corners = set([labels[0, 0], labels[0, w-1], labels[h-1, 0], labels[h-1, w-1]])\n",
    "    return corners\n",
    "\n",
    "\n",
    "def calculate_objects_size(labels, corners):\n",
    "    object_sizes = Counter(labels.ravel())\n",
    "    for corner in corners:\n",
    "        del object_sizes[corner]\n",
    "    return object_sizes\n",
    "\n",
    "\n",
    "def sort_labels_by_size(object_sizes):\n",
    "    sorted_sizes = sorted(object_sizes.items(), key=lambda x: x[1])\n",
    "    return sorted_sizes\n",
    "\n",
    "\n",
    "def remove_small_objects(sorted_sizes):\n",
    "    filtered_sizes = [size_tuple for size_tuple in sorted_sizes if size_tuple[1] > 1000]\n",
    "    return filtered_sizes\n",
    "\n",
    "\n",
    "def remove_diaphragm(labels, filtered_sizes):\n",
    "    h, w = labels.shape[:2]\n",
    "    st = set()\n",
    "\n",
    "    for i in range(h):\n",
    "        if (labels[i, i],) in filtered_sizes:\n",
    "            st.add((labels[i, i],))\n",
    "\n",
    "        if (labels[h-i-1, i],) in filtered_sizes:\n",
    "            st.add((labels[h-i-1, i],))\n",
    "\n",
    "        if (labels[h-i-1, w-i-1],) in filtered_sizes:\n",
    "            st.add((labels[h-i-1, w-i-1],))\n",
    "\n",
    "    filtered_sizes = list(set(filtered_sizes) - st)\n",
    "\n",
    "    diaphragm_label = label if label in labels else None\n",
    "    \n",
    "    return diaphragm_label\n",
    "\n",
    "def create_cleaned_labels(labels, filtered_sizes):\n",
    "    cleaned_labels = np.zeros_like(labels)\n",
    "    for size_tuple in filtered_sizes:\n",
    "        obj_label = size_tuple[0]\n",
    "        obj_mask = np.where(labels == obj_label, 1, 0)\n",
    "        cleaned_labels += obj_mask * obj_label\n",
    "    return cleaned_labels\n",
    "\n",
    "\n",
    "def get_left_and_right_labels(labels):\n",
    "    regions = measure.regionprops(labels)\n",
    "    centroids = [r.centroid for r in regions]\n",
    "    \n",
    "    # Sort the centroids based on their x-coordinate values\n",
    "    centroids.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Find the two objects with smallest x-coordinates\n",
    "    left_obj_centroid, right_obj_centroid = centroids[:2]\n",
    "    left_label, right_label = None, None\n",
    "    for region in regions:\n",
    "        if tuple(region.centroid) == tuple(left_obj_centroid):\n",
    "            left_label = region.label\n",
    "        elif tuple(region.centroid) == tuple(right_obj_centroid):\n",
    "            right_label = region.label\n",
    "            \n",
    "    return left_label, right_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(slice,flag=0):\n",
    "    '''convert image to gray scale'''\n",
    "    if len(slice.shape) == 3:\n",
    "        slice = rgb2gray(slice)\n",
    "    else:\n",
    "        slice = slice\n",
    "        \n",
    "    '''normalize values in image to be in range 0 for 1'''\n",
    "    img_eq = normalize(slice)\n",
    "    \n",
    "    '''binarize image to remove back ground'''\n",
    "    thresh = filters.threshold_isodata(img_eq)\n",
    "    binary =( img_eq< thresh)\n",
    "\n",
    "    '''label images for detect objects in image'''\n",
    "    labels, nlabels = ndi.label(binary)\n",
    "    '''this filter_labels function for returning left and right lungs from objects in the image'''\n",
    "    try:\n",
    "        first, second = filter_labels(labels, nlabels)\n",
    "            \n",
    "    except:\n",
    "        return np.zeros((256, 256, 3))\n",
    "\n",
    "    '''this line to extract two lungs with their colors from the main image'''\n",
    "    lungs= np.where((labels == first) | (labels == second),1,0) * slice\n",
    "\n",
    "    '''this for get bounded lungs from image and resize image to make all images with same size'''\n",
    "    bboxes= ndi.find_objects(np.where((labels == first) | (labels == second),1,0))\n",
    "    im_res= slice[bboxes[0]]\n",
    "    new_size = (256, 256)\n",
    "    \n",
    "    image_resized = resize(im_res, new_size, order=0, mode='reflect', anti_aliasing=False)\n",
    "    \n",
    "    sharpened_image = filters.unsharp_mask(image_resized, radius=1, amount=1)\n",
    "    \n",
    "    if flag:\n",
    "        show_slices([slice,img_eq,binary,labels,lungs,sharpened_image],3,2)\n",
    "\n",
    "    return gray2rgb(sharpened_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread('./iqothnccd-lung-cancer-dataset/The IQ-OTHNCCD lung cancer dataset/Malignant cases/Malignant case (10).jpg')\n",
    "res = segmentation(img,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preparing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Initialize variables\n",
    "data = []\n",
    "img_size = 256\n",
    "\n",
    "# Loop over categories and their files\n",
    "for i, category in enumerate(categories):\n",
    "    for file in os.listdir(os.path.join(directory, category)):\n",
    "        img = cv2.imread(os.path.join(directory, category, file), 0)\n",
    "        \n",
    "        # Preprocess image and skip if maximum pixel value is 0\n",
    "        img = segmentation(img)\n",
    "        if img.max() == 0:\n",
    "            continue\n",
    "        \n",
    "        # Append image and label to data list\n",
    "        data.append([img, i])\n",
    "\n",
    "# Shuffle data randomly\n",
    "random.shuffle(data)\n",
    "\n",
    "# Extract features and labels from data\n",
    "X, y = [], []\n",
    "for feature, label in data:\n",
    "    X.append(feature)\n",
    "    y.append(label)\n",
    "\n",
    "# X, y = zip(*data)\n",
    "\n",
    "# Print length of X and count of each unique value in y\n",
    "print('X length:', len(X))\n",
    "print('y counts:', Counter(y))\n",
    "\n",
    "# Convert features and labels to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_slices(X,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Apply smoting for avoid bias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smote(X_train, y_train):\n",
    "    # Flatten each image in X_train\n",
    "    X_train_flat = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "\n",
    "    # Print the distribution of classes before applying SMOTE\n",
    "    print(\"Class Distribution Before SMOTE:\", Counter(y_train))\n",
    "\n",
    "    # Apply SMOTE to balance the training set\n",
    "    smote = SMOTE()\n",
    "    X_train_sampled, y_train_sampled = smote.fit_resample(X_train_flat, y_train.ravel())\n",
    "\n",
    "    # Reshape the flattened images back to their original shape\n",
    "    X_train_sampled = np.reshape(X_train_sampled, (X_train_sampled.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3]))\n",
    "\n",
    "    # Print the distribution of classes after applying SMOTE\n",
    "    print(\"Class Distribution After SMOTE:\", Counter(y_train_sampled))\n",
    "\n",
    "    return X_train_sampled, y_train_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sampled, y_train_sampled = apply_smote(X_train, y_train)\n",
    "X_valid_sampled, y_valid_sampled = apply_smote(X_valid, y_valid)\n",
    "X_test_sampled, y_test_sampled = apply_smote(X_test, y_test)\n",
    "\n",
    "print('X_train_sampled',X_train_sampled.shape)\n",
    "print('X_valid_sampled',X_valid_sampled.shape)\n",
    "print('X_test_sampled',X_test_sampled.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.applications import VGG16\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create an instance of the VGG16 model with pre-trained weights\n",
    "vgg = VGG16(weights='imagenet', include_top=False, input_shape=X_train_sampled.shape[1:])\n",
    "\n",
    "# Freeze the convolutional layers in the base model so they are not updated during training\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add your own classification layers on top of the base model\n",
    "model = Sequential()\n",
    "model.add(vgg)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Use data augmentation to generate additional training data\n",
    "datagen_train = ImageDataGenerator()\n",
    "datagen_val = ImageDataGenerator()\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_sampled, y_train_onehot, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42)\n",
    "\n",
    "# Compile the model with a lower learning rate and categorical hinge loss\n",
    "opt = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss='categorical_hinge', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping criteria to prevent overfitting\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using the augmented data generator and early stopping\n",
    "history = model.fit(datagen_train.flow(X_train, y_train, batch_size=9, shuffle=True),\n",
    "                    epochs=10,\n",
    "                    validation_data=datagen_val.flow(X_val, y_val, batch_size=9, shuffle=True),\n",
    "                    callbacks=[early_stop],\n",
    "                    shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
